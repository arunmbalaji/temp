{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market-1501 Train dataset\n",
    "\n",
    "This notebook splits the Market1501 train dataset into train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set  up  accounts and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('./src')\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Configure train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "raw_bucket=\"<<bucketname>\" # e.g. mybucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3 input data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_raw = \"s3://{}/merket1501/bounding_box_train/\".format(raw_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3 destination source\n",
    "This is where the split train into train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train=\"s3://{}/market1501/train3/\".format(bucket)\n",
    "s3_train_lst=\"s3://{}/market1501/train3_lst/\".format(bucket)\n",
    "\n",
    "\n",
    "s3_val=\"s3://{}/market1501/val3/\".format(bucket)\n",
    "s3_val_lst=\"s3://{}/market1501/val3_lst/\".format(bucket)\n",
    "\n",
    "\n",
    "s3_output_path= \"s3://{}/market1501_output/\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir=\"/tmp/imageebedding\"\n",
    "train_raw_dir = os.path.join(temp_dir, \"train_raw\")\n",
    "train_lst= os.path.join(temp_dir, \"train_raw\", \"train.lst\")\n",
    "val_raw_dir = os.path.join(temp_dir, \"val_raw\")\n",
    "val_lst= os.path.join(temp_dir, \"val_raw\", \"val.lst\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $temp_dir \n",
    "!mkdir  -p $temp_dir \n",
    "!mkdir -p  $train_raw_dir\n",
    "!mkdir -p  $val_raw_dir\n",
    "!aws s3 sync $s3_train_raw $train_raw_dir --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.market1501_dataset import Market1501Dataset\n",
    "\n",
    "dataset = Market1501Dataset(train_raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(train_raw_dir, f) for f in os.listdir(train_raw_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "# The market 1501 dataset files have the naming convention target_camerasite_..., e.g. 1038_c2s2_131202_03.jpeg\n",
    "target_raw_labels = [os.path.basename(f).split(\"_\")[0] for f in files]\n",
    "zero_indexed_labels_dict = {}\n",
    "for rc in target_raw_labels:\n",
    "    zero_indexed_labels_dict[rc] = zero_indexed_labels_dict.get(rc, len(zero_indexed_labels_dict))\n",
    "\n",
    "target_zero_indexed_labels = [zero_indexed_labels_dict[l] for l in target_raw_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3://sagemaker-us-east-2-324346001917/market1501/train/\n",
    "len(zero_indexed_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_train, class_val = train_test_split( list(zero_indexed_labels_dict.values()),  test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain_x = [f for f,l in zip(files, target_zero_indexed_labels) if l in class_train]\n",
    "datatrain_y = [l for f,l in zip(files, target_zero_indexed_labels) if l in class_train]\n",
    "\n",
    "\n",
    "dataval_x = [f for f,l in zip(files, target_zero_indexed_labels) if l in class_val]\n",
    "dataval_y = [l for f,l in zip(files, target_zero_indexed_labels) if l in class_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.DataFrame.from_records([(i,)for i in dataval_y])\n",
    "df_val.columns=[\"target\"]\n",
    "df_train = pd.DataFrame.from_records([(i,)for i in datatrain_y])\n",
    "df_train.columns=[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"target\"].value_counts().plot.bar(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"target\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"target\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"target\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def upload_files(files, s3_dest, num_threads=10 ):\n",
    "    input_tuples = ( (f,  s3_dest) for f in files)\n",
    "\n",
    "    with ThreadPool(num_threads) as pool:\n",
    "        pool.starmap(upload_file, input_tuples)\n",
    "   \n",
    "    \n",
    "\n",
    "def upload_file(f, s3_dest):\n",
    "    fname=os.path.basename(f)\n",
    "    prefix = \"/\".join( s3_dest.split(\"//\")[1].split(\"/\")[1:])\n",
    "    key = \"{}/{}\".format(prefix.strip(\"/\"), fname)\n",
    "    bucket_d = s3_dest.split(\"//\")[1].split(\"/\")[0]\n",
    "    s3_client.upload_file(f,   bucket_d, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "upload_files(dataval_x, s3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "upload_files(datatrain_x, s3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train, s3_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
